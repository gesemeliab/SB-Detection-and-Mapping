# SB-Detection-and-Mapping (SBDM)

[![ROS](https://img.shields.io/badge/ROS-Melodic%20%7C%20Noetic-blue)](http://wiki.ros.org/)
[![Python](https://img.shields.io/badge/Python-3.6%2B-brightgreen)](https://www.python.org/)
[![C++](https://img.shields.io/badge/C%2B%2B-11-orange)](https://isocpp.org/)
[![License](https://img.shields.io/badge/License-GPLv3-red)](./LICENSE)
[![Code Quality](https://img.shields.io/badge/Code%20Quality-Production%20Ready-success)](./REFACTORING.md)

**An image processing + deep learning approach to detect and map strawberries with a robotic platform**

SBDM is a professional ROS-based system that combines computer vision, deep learning, and SLAM to detect and spatially map strawberries in agricultural fields using a mobile robot equipped with a ZED stereo camera.

**Authors:** Gesem Gudi√±o, Andres Montes de Oca, and Gerardo Flores

## üéØ Key Features

- ‚úÖ **Real-time Detection**: LAB color space filtering + CNN classification
- ‚úÖ **3D Localization**: Stereo depth + coordinate transformation for world-frame mapping
- ‚úÖ **Production Ready**: Professional OOP architecture with comprehensive error handling
- ‚úÖ **Highly Configurable**: ROS parameter server integration (no code changes needed)
- ‚úÖ **Well Documented**: 1000+ lines of documentation and developer guides
- ‚úÖ **Maintainable**: SOLID principles, type hints, and clean code practices

## üìö Documentation

- **[REFACTORING_SUMMARY.md](./REFACTORING_SUMMARY.md)** - Executive summary of code quality improvements
- **[ARCHITECTURE.md](./ARCHITECTURE.md)** - System architecture and design patterns
- **[DEVELOPER_GUIDE.md](./DEVELOPER_GUIDE.md)** - Complete development guide
- **[MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md)** - Transition from legacy to refactored code
- **[REFACTORING.md](./REFACTORING.md)** - Detailed technical improvements analysis

## üöÄ Quick Start (Refactored Version)

### Single Command Launch
```bash
# Start complete pipeline (TF broadcaster + detector + plotter)
roslaunch sb_detection detection_pipeline.launch \
    model_path:=/path/to/your/model.h5 \
    confidence_threshold:=0.98 \
    rviz:=true
```

### With ZED Camera
```bash
# Terminal 1: Start ZED camera
roslaunch zed_wrapper zedm.launch

# Terminal 2: Start detection pipeline
roslaunch sb_detection detection_pipeline.launch model_path:=/path/to/model.h5
```

## üìñ Traditional Usage (Legacy Compatible)

# License
SBDM released under a [GPLv3 license](https://github.com/gesemeliab/SB-Detection-and-Mapping/blob/main/LICENSE)

# Install

## Prerequisites

The necessary prerequisites are found in hector_slam -> (https://github.com/tu-darmstadt-ros-pkg/hector_slam) and  zed_ros_wrapper ->(https://github.com/stereolabs/zed-ros-wrapper):

- OpenCV
- Keras
- ROS
- zed_ros_wrapper
- hector_slam

## Building SBDM

Change the name of the catkin workspace to yours.

```
mkdir sbdm_ws; cd sbdm_ws; mkdir src; cd src
git clone https://github.com/gesemeliab/SB-Detection-and-Mapping.git
cd ..
catkin_make
```
After compilation pleas do:

source ~/sbdm_ws/devel/setup.bash

# Run

To run this code you first have to have connected your ZED stereo camera with its respective SDK. You can find it in (https://www.stereolabs.com/developers/release/)

Next you will need to launch the zed_ros_wrapper.

ZED camera:

    roslaunch zed_wrapper zed.launch
   
ZED Mini camera:

    roslaunch zed_wrapper zedm.launch

### Original Method (Still Supported)
```bash
# Start broadcaster
roslaunch broadcaster rover.launch

# Start detector (Note: Set model path in code first)
rosrun sb_detection SBDetection.py

# Start plotter
rosrun plotting_points sb_plotter.py

# Optional: Visualize trajectory
rosrun hector_trajectory_server hector_trajectory_server
```

## üèóÔ∏è Architecture Highlights

The refactored codebase demonstrates professional software engineering:

### Modular Design
```
sb_detection/
‚îú‚îÄ‚îÄ config.py           # Configuration management
‚îú‚îÄ‚îÄ vision_utils.py     # CV utilities (7 focused classes)
‚îú‚îÄ‚îÄ classifier.py       # CNN model wrapper
‚îî‚îÄ‚îÄ detection_node.py   # Main ROS node (OOP)
```

### Key Improvements Over Legacy Code
- ‚úÖ **Configuration**: ROS parameters vs hardcoded values
- ‚úÖ **Error Handling**: Comprehensive validation vs silent failures
- ‚úÖ **Documentation**: Full docstrings vs minimal comments
- ‚úÖ **Logging**: Structured ROS logging vs print statements
- ‚úÖ **Testability**: Modular components vs monolithic functions
- ‚úÖ **Type Safety**: Python type hints throughout
- ‚úÖ **Code Quality**: PEP8 compliant, SOLID principles

See [REFACTORING_SUMMARY.md](./REFACTORING_SUMMARY.md) for details.

## üîß Configuration Parameters

### Detection Node
- `model_path` - Path to trained CNN model (required)
- `confidence_threshold` - Min confidence for detection (default: 0.98)
- `focal_length` - Camera focal length in pixels (default: 1396.91)
- `lab_a_threshold` - LAB color space threshold (default: 165)
- `central_region_ratio` - ROI width ratio (default: 0.05)

### Example Custom Configuration
```bash
roslaunch sb_detection detection_pipeline.launch \
    model_path:=/path/to/model.h5 \
    confidence_threshold:=0.95 \
    focal_length:=1400.0 \
    lab_a_threshold:=160
```

See [MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md) for all parameters.

# Data Base

You can find the data base used for this work in (https://github.com/gesemeliab/SB-Detection-and-Mapping/tree/main/database) where you will find two directories.

 ## h5
 
 An already created database for training purpose, this file contains 520 labeled images of green and red strawberries with shape (128,128,3), they are in the A channel of the CIE LAB color space and pixels are between 0 and 1.
 
## images
 
In images directory you will find two sub-directories:
- **complete/**: Natural RGB images taken in farmlands (~88 high-resolution images)
- **cropped/**: Extracted strawberry patches in RGB format for training

## ü§ù Contributing

We welcome contributions! Please:

1. Read [DEVELOPER_GUIDE.md](./DEVELOPER_GUIDE.md) for coding standards
2. Follow the established architecture patterns
3. Add tests for new features
4. Update documentation

## üéì For Developers

### Code Quality Showcase

This codebase demonstrates professional software engineering practices suitable for:
- Senior robotics engineer positions
- Research publications
- Production deployments
- Team collaboration projects

**Key Highlights:**
- Object-oriented design with SOLID principles
- Comprehensive error handling and logging
- Type hints and documentation (1000+ lines)
- Configuration management via ROS parameters
- Clean code practices (PEP8, Google C++ Style)
- Modular architecture enabling easy testing

See [REFACTORING_SUMMARY.md](./REFACTORING_SUMMARY.md) for a complete analysis.

### Project Structure
```
SB-Detection-and-Mapping/
‚îú‚îÄ‚îÄ broadcaster/          # C++ TF broadcasting (legacy + refactored)
‚îú‚îÄ‚îÄ sb_detection/         # Python detection node (legacy + refactored)
‚îú‚îÄ‚îÄ plotting_points/      # Python visualization (legacy + refactored)
‚îú‚îÄ‚îÄ database/             # Training data (HDF5 + images)
‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îú‚îÄ‚îÄ ARCHITECTURE.md       # System architecture diagrams
‚îú‚îÄ‚îÄ DEVELOPER_GUIDE.md    # Development guide
‚îú‚îÄ‚îÄ MIGRATION_GUIDE.md    # Legacy ‚Üí Refactored guide
‚îú‚îÄ‚îÄ REFACTORING.md        # Technical improvements analysis
‚îî‚îÄ‚îÄ REFACTORING_SUMMARY.md # Executive summary
```

## üìä Performance

- **Detection Rate**: Real-time (synchronized with camera frame rate)
- **Classification**: CNN inference with GPU acceleration
- **Localization**: 3D coordinate transformation with depth validation
- **No Performance Degradation**: Refactoring maintains identical throughput

## üêõ Troubleshooting

### Common Issues

**Model not found:**
```bash
rosparam set /strawberry_detector/model_path /full/path/to/model.h5
```

**No detections:**
- Check camera topics: `rostopic list | grep zedm`
- Verify image stream: `rqt_image_view /zedm/zed_node/left/image_rect_color`
- Check debug image: `rqt_image_view /debug_image`

**TF errors:**
```bash
rosrun rqt_tf_tree rqt_tf_tree  # Visualize TF tree
rosrun tf tf_echo world camera  # Check specific transform
```

See [MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md) for detailed troubleshooting.

## üìÑ Citation

If you use this work in your research, please cite:

```bibtex
@misc{sbdm2025,
  author = {Gudi√±o, Gesem and Montes de Oca, Andres and Flores, Gerardo},
  title = {SB-Detection-and-Mapping: Strawberry Detection and Mapping with Deep Learning},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/gesemeliab/SB-Detection-and-Mapping}
}
```

## üìû Contact

For questions, issues, or collaboration opportunities:
- Open an issue on GitHub
- See [DEVELOPER_GUIDE.md](./DEVELOPER_GUIDE.md) for contribution guidelines

## ‚≠ê Acknowledgments

- ZED stereo camera SDK by Stereolabs
- ROS ecosystem and community
- Hector SLAM for trajectory visualization

---

**Note**: Both legacy and refactored code are maintained for backward compatibility. New users should use the refactored version via `detection_pipeline.launch`. See [MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md) for transition instructions.
